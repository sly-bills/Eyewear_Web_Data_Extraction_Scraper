{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819c069d",
   "metadata": {},
   "source": [
    "## Importing Librariees and Webdrivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ac56da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Used\n",
    "import csv\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait as WDW\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ed704ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the Web Driver...\n",
      "Done setting up..\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Configuration and Data Fetching\n",
    "# Setup Selenium and WebDriver\n",
    "print(\"Setting up the Web Driver...\")\n",
    "chrome_option = Options()\n",
    "chrome_option.add_argument('--headless')\n",
    "chrome_option.add_argument('--disable-gpu')\n",
    "chrome_option.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.6778.265 Safari/537.36\"\n",
    ")\n",
    "print(\"Done setting up..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "065e915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing Chrome WebDriver...\n",
      "final setup\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Install the chrome driver (This is a one-time setup)\n",
    "print(\"Installing Chrome WebDriver...\")\n",
    "service = Service(ChromeDriverManager().install())\n",
    "print(\"final setup\")\n",
    "driver = webdriver.Chrome(service=service, options=chrome_option)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9f9345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting webpage: https://www.framesdirect.com/eyeglasses\n",
      "Waiting for products to load...\n",
      "Done...Proceed to parse the data\n"
     ]
    }
   ],
   "source": [
    "target_url = \"https://www.framesdirect.com/eyeglasses\"\n",
    "print(f\"Visiting webpage: {target_url}\")\n",
    "driver.get(target_url)\n",
    "\n",
    "# Further Instruction: Wait for JS to load the files. \n",
    "try:\n",
    "    print(\"Waiting for products to load...\")\n",
    "    WDW(driver, 15).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, 'fd-cat'))\n",
    "    )\n",
    "    print(\"Done...Proceed to parse the data\")\n",
    "except (TimeoutError, Exception) as e:\n",
    "    print(f\"Error, waiting for {target_url}: {e}\")\n",
    "    driver.quit()\n",
    "    print(\"closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62d6acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Data Parsing and Extraction\n",
    "# Get page source and parse using BeautifulSoup\n",
    "content = driver.page_source\n",
    "page = BeautifulSoup(content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ff021ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 products. Extracting data...\n",
      "Saved 25 records to CSV file\n",
      "Saved 25 records to JSON file\n",
      "End of Web Scraping\n"
     ]
    }
   ],
   "source": [
    "# Temporary storage for the extracted data\n",
    "eyeglasses_data = []\n",
    "seen = set()  # to track duplicates based on (brand, product_name)\n",
    "\n",
    "\n",
    "# Locate all product files and extract relevant data\n",
    "product_holders = page.find_all('div', class_='prod-holder')\n",
    "print(f\"Found {len(product_holders)} products. Extracting data...\")\n",
    "\n",
    "for holder in product_holders:\n",
    "    prod_title = holder.find('div', class_='prod-title')\n",
    "\n",
    "    if prod_title:\n",
    "        brand_tag = prod_title.find('div', class_='catalog-name')\n",
    "        brand = brand_tag.text.strip() if brand_tag else \"N/A\"\n",
    "\n",
    "        name_tag = prod_title.find('div', class_='product_name')\n",
    "        name = name_tag.text.strip() if name_tag else \"N/A\"\n",
    "\n",
    "        # For Price\n",
    "        price_cnt = holder.find('div', class_='prod-price-wrap')\n",
    "        if price_cnt:\n",
    "            # Current Price\n",
    "            current_price_tag = price_cnt.find('div', class_='prod-aslowas')\n",
    "            current_price = current_price_tag.text.strip() if current_price_tag else \"N/A\"\n",
    "\n",
    "            # Former Price\n",
    "            former_price_tag = price_cnt.find('div', class_='prod-catalog-retail-price')\n",
    "            former_price = former_price_tag.text.strip() if former_price_tag else \"N/A\"\n",
    "        else:\n",
    "            original_price = former_price = \"N/A\"\n",
    "\n",
    "    discount_tag = holder.find('div', class_='frame-discount')\n",
    "    discount = discount_tag.text.strip() if discount_tag else \"N/A\"\n",
    "\n",
    "    # Create unique key (Brand + Name)\n",
    "    unique_key = (brand, name) # Checks for duplicates\n",
    "\n",
    "    if unique_key not in seen:\n",
    "        seen.add(unique_key)  # mark as seen\n",
    "    data = {\n",
    "            \"brand\": brand,\n",
    "            \"name\": name,\n",
    "            \"current_price\": current_price,\n",
    "            \"former_price\": former_price,\n",
    "            \"discount\": discount\n",
    "    }\n",
    "\n",
    "    # Append data to the list\n",
    "    eyeglasses_data.append(data)\n",
    "\n",
    "\n",
    "# Step 3 - Data Storage and Finalization\n",
    "# Save the data to a CSV file\n",
    "column_name = eyeglasses_data[0].keys() # Get Column names from the first dictionary\n",
    "with open('framesdirectdotcom_data.csv', mode='w', newline='', encoding='utf-8') as csv_file: # Open up the file with context manager\n",
    "    dict_writer = csv.DictWriter(csv_file, fieldnames=column_name) # Create a DictWriter object\n",
    "    dict_writer.writeheader() # Write the header row\n",
    "    dict_writer.writerows(eyeglasses_data) # Write all the data rows\n",
    "print (f\"Saved {len(eyeglasses_data)} records to CSV file\")\n",
    "\n",
    "# Save the data to a JSON file\n",
    "with open(\"framesdirectdotcom.json\", mode='w') as json_file:\n",
    "    json.dump(eyeglasses_data, json_file, indent=4)\n",
    "print(f\"Saved {len(eyeglasses_data)} records to JSON file\")\n",
    "\n",
    "# Close the browser and quit the driver\n",
    "driver.quit()\n",
    "print(\"End of Web Scraping\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
